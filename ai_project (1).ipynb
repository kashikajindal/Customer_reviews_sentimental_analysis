{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9430fe55-7fe2-48e1-a8f7-d3296f04b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb92bba2-45c2-4469-b51e-1d9a6885665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a28e781-8f56-4721-9b39-2a55c83cf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa8ac83-2afb-4652-9478-2365dda1d3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love your coffee</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did not like the format of the store, the ba...</td>\n",
       "      <td>3 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rico and his hot and delicious muffin sausages...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad service and they always forget to put the ...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought two meals from them for my friends, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews   rating\n",
       "0                                 I love your coffee  5 stars\n",
       "1  I did not like the format of the store, the ba...  3 stars\n",
       "2  Rico and his hot and delicious muffin sausages...  5 stars\n",
       "3  Bad service and they always forget to put the ...   1 star\n",
       "4  I bought two meals from them for my friends, a...   1 star"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"MCDONALD3.csv\", encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64c9478-7cba-4e20-814e-ed5793205ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_10964\\3833925203.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['rating_num'] = df['rating'].str.extract('(\\d)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "df['rating_num'] = df['rating'].str.extract('(\\d)').astype(int)\n",
    "\n",
    "def convert_rating_to_label(rating):\n",
    "    if rating <= 2:\n",
    "        return \"Negative\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "df['label'] = df['rating_num'].apply(convert_rating_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c214766f-f8d3-4f95-b8ce-237f11dc3247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love your coffee</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did not like the format of the store, the ba...</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rico and his hot and delicious muffin sausages...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad service and they always forget to put the ...</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought two meals from them for my friends, a...</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews   rating  rating_num  \\\n",
       "0                                 I love your coffee  5 stars           5   \n",
       "1  I did not like the format of the store, the ba...  3 stars           3   \n",
       "2  Rico and his hot and delicious muffin sausages...  5 stars           5   \n",
       "3  Bad service and they always forget to put the ...   1 star           1   \n",
       "4  I bought two meals from them for my friends, a...   1 star           1   \n",
       "\n",
       "      label  \n",
       "0  Positive  \n",
       "1   Neutral  \n",
       "2  Positive  \n",
       "3  Negative  \n",
       "4  Negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afddc0b5-0021-40e9-a274-3aa2505da3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered = [i for i in tokens if i not in stop_words]\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered]\n",
    "    return lemmatized\n",
    "\n",
    "df['tokens'] = df['reviews'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79ef189-15c7-4bf5-a829-f054dedbeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for tokens in df['tokens']:\n",
    "   vocab.update(tokens)\n",
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5f3c1e-d98f-4f7c-b96d-7d2ebe2cba3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethical',\n",
       " 'explained',\n",
       " 'start',\n",
       " 'washroom',\n",
       " 'whatever',\n",
       " 'yelling',\n",
       " 'received',\n",
       " 'district',\n",
       " 'laptop',\n",
       " 'issue',\n",
       " 'flooded',\n",
       " 'doughy',\n",
       " 'j',\n",
       " 'tol',\n",
       " 'blow',\n",
       " 'roanoke',\n",
       " 'caught',\n",
       " 'okay.have',\n",
       " 'macdonaldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½s',\n",
       " 'andi',\n",
       " 'neat',\n",
       " 'usally',\n",
       " 'micky',\n",
       " 'mcrib',\n",
       " 'treated',\n",
       " 'discount',\n",
       " 'loving',\n",
       " 'tough',\n",
       " 'stale',\n",
       " 'smelly',\n",
       " 'disregard',\n",
       " 'cb',\n",
       " 'false',\n",
       " 'everytime',\n",
       " 'notignoring',\n",
       " '5th',\n",
       " 'cutter',\n",
       " 'salad',\n",
       " 'lid',\n",
       " 'mobile',\n",
       " 'hill',\n",
       " 'continue',\n",
       " 'kindly',\n",
       " 'daughterï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½s',\n",
       " 'arcade',\n",
       " 'alternative',\n",
       " 'dropping',\n",
       " 'rotten',\n",
       " 'traveling',\n",
       " 'rehn',\n",
       " 'ppace',\n",
       " 'six',\n",
       " 'rap',\n",
       " 'company',\n",
       " 'vacationer',\n",
       " 'addition',\n",
       " 'though',\n",
       " 'floating',\n",
       " 'tablespoon',\n",
       " 'bun',\n",
       " 'shouldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ve',\n",
       " 'afraid',\n",
       " 'showed',\n",
       " 'bummed',\n",
       " 'another',\n",
       " 'refill',\n",
       " 'friendly',\n",
       " '10:15',\n",
       " 'crunch',\n",
       " 'bisque',\n",
       " 'trouble',\n",
       " 'requested',\n",
       " 'mate',\n",
       " 'aquatica',\n",
       " 'n64',\n",
       " 'fiend',\n",
       " '48',\n",
       " 'literal',\n",
       " 'darned',\n",
       " 'living',\n",
       " 'fw',\n",
       " 'rainy',\n",
       " 'healthier',\n",
       " 'bday',\n",
       " 'website',\n",
       " 'however',\n",
       " 'yup',\n",
       " 'met',\n",
       " 'wednesday',\n",
       " 'factor',\n",
       " 'rear',\n",
       " 'amout',\n",
       " 'bored',\n",
       " 'automac',\n",
       " 'barrier',\n",
       " 'coordinating',\n",
       " 'site',\n",
       " 'macdonalds',\n",
       " 'tird',\n",
       " 'salted',\n",
       " 'reputable',\n",
       " 'proactive',\n",
       " 'state',\n",
       " 'removed',\n",
       " 'lacked',\n",
       " 'ate',\n",
       " 'hashbrowns',\n",
       " 'donaldï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'venue',\n",
       " '2.',\n",
       " '5min',\n",
       " 'tiger',\n",
       " 'stomp',\n",
       " 'placed',\n",
       " 'modern',\n",
       " 'accurately',\n",
       " 'museum',\n",
       " 'someone',\n",
       " 'named',\n",
       " 'ensure',\n",
       " 'garden',\n",
       " 'drivetrue',\n",
       " 'king',\n",
       " 'worker',\n",
       " 'peice',\n",
       " '12:40',\n",
       " '11:30',\n",
       " 'leaving',\n",
       " 'abd',\n",
       " 'mcdonaldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'resolution',\n",
       " 'donaldï¿½ï¿½',\n",
       " 'spanish',\n",
       " 'tad',\n",
       " 'war',\n",
       " 'thatï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'mango',\n",
       " 'playplace',\n",
       " 'diligently',\n",
       " 'container',\n",
       " 'ghetto',\n",
       " 'leave',\n",
       " 'telling',\n",
       " 'zacharine',\n",
       " 'speed',\n",
       " 'offering',\n",
       " 'stead',\n",
       " 'shame',\n",
       " '2/3',\n",
       " 'ok.',\n",
       " 'tolerate',\n",
       " 'route',\n",
       " 'auto',\n",
       " 'racism',\n",
       " 'movement',\n",
       " 'ordering',\n",
       " 'various',\n",
       " 'twenty',\n",
       " 'crutry',\n",
       " 'upgradeable',\n",
       " 'instead',\n",
       " 'ridiculously',\n",
       " 'dummy',\n",
       " 'properï¿½ï¿½ï¿',\n",
       " 'cafe',\n",
       " 'aau',\n",
       " 'extremely',\n",
       " 'generous',\n",
       " 'mind',\n",
       " 'loud',\n",
       " 'shutdown',\n",
       " 'stasiuk',\n",
       " 'dispensor',\n",
       " 'soul',\n",
       " 'hv',\n",
       " 'surroundings',\n",
       " 'drove',\n",
       " 'a.m.',\n",
       " 'admit',\n",
       " \"n't\",\n",
       " 'play',\n",
       " 'deciding',\n",
       " 'alright',\n",
       " '1989',\n",
       " 'nephew',\n",
       " 'cudos',\n",
       " 'arrive',\n",
       " 'moment',\n",
       " \"'s\",\n",
       " 'mcflurries',\n",
       " 'macdonald',\n",
       " 'jennifer',\n",
       " 'beat',\n",
       " 'creole',\n",
       " 'starving',\n",
       " 'understandable',\n",
       " 'cleanliness',\n",
       " 'course',\n",
       " 'housing',\n",
       " 'properly',\n",
       " 'mopped',\n",
       " 'improvement',\n",
       " 'ticket',\n",
       " 'kasey',\n",
       " 'speedy',\n",
       " 'rudely',\n",
       " 'utter',\n",
       " 'playhouse',\n",
       " 'roomy',\n",
       " 'prime',\n",
       " 'begging',\n",
       " 'deal',\n",
       " 'newly',\n",
       " '7/16',\n",
       " 'anyoneï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'walking',\n",
       " 'ver',\n",
       " 'simple',\n",
       " 'calorie',\n",
       " 'composure',\n",
       " 'dressing',\n",
       " 'stellar',\n",
       " 'leasy',\n",
       " '6:30am',\n",
       " 'retrain',\n",
       " 'multiple',\n",
       " 'soda',\n",
       " 'many',\n",
       " 'chik',\n",
       " 'paper',\n",
       " 'built',\n",
       " 'photo',\n",
       " 'conclusion',\n",
       " 'swing',\n",
       " 'difficult',\n",
       " 'seen',\n",
       " 'beware',\n",
       " 'straight',\n",
       " 'disarray',\n",
       " 'drive',\n",
       " 'ground',\n",
       " 'interstate',\n",
       " 'stephanie',\n",
       " 'attempted',\n",
       " 'wish',\n",
       " 'feel',\n",
       " 'hispanic',\n",
       " 'interesting',\n",
       " 'wrong',\n",
       " 'healthy',\n",
       " 'refrigerated',\n",
       " 'maybe',\n",
       " 'diabetic',\n",
       " 'eternity',\n",
       " '32',\n",
       " 'insisting',\n",
       " 'c',\n",
       " 'line',\n",
       " 'unsanitary',\n",
       " 'cassandra',\n",
       " 'period',\n",
       " 'mark',\n",
       " 'always',\n",
       " 'condiment',\n",
       " 'audacity',\n",
       " 'taker',\n",
       " 'anything',\n",
       " 'opinion',\n",
       " 'pitiful',\n",
       " 'variety',\n",
       " 'moron',\n",
       " 'within',\n",
       " 'looking',\n",
       " 'adamant',\n",
       " 'cash',\n",
       " 'tested',\n",
       " 'supervisor',\n",
       " 'allservice',\n",
       " 'approximately',\n",
       " 'ahead',\n",
       " 'wack',\n",
       " '2-6',\n",
       " 'session',\n",
       " 'waist',\n",
       " 'brunch',\n",
       " 'grunt',\n",
       " 'jungle',\n",
       " 'tattoo',\n",
       " 'wicked',\n",
       " 'valuable',\n",
       " '15',\n",
       " 'ahoy',\n",
       " 'convenient',\n",
       " 'client',\n",
       " '25',\n",
       " 'fire',\n",
       " '/',\n",
       " 'wiff',\n",
       " 'mcdonaldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½s',\n",
       " 'occasionally',\n",
       " 'upscaling',\n",
       " 'typically',\n",
       " 'slacker',\n",
       " 'thinking',\n",
       " 'edible',\n",
       " 'ou',\n",
       " 'talk',\n",
       " 'ten',\n",
       " 'glob',\n",
       " 'considered.use',\n",
       " 'easily',\n",
       " 'ala',\n",
       " 'child',\n",
       " 'little',\n",
       " 'unfriendly',\n",
       " 'self-ordering',\n",
       " 'reliability',\n",
       " 'overcooked',\n",
       " 'uniform',\n",
       " 'weird',\n",
       " 'carefull',\n",
       " 'outdoor',\n",
       " 'texas',\n",
       " 'lettuce',\n",
       " 'tear',\n",
       " 'moaning',\n",
       " 'kinda',\n",
       " 'five-star',\n",
       " 'advertise',\n",
       " 'cheerful',\n",
       " 'hated',\n",
       " 'ok.the',\n",
       " 'disappoint',\n",
       " 'repair',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½one',\n",
       " 'donï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'talked',\n",
       " 'all-day',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'focus',\n",
       " 'grapevine',\n",
       " 'passed',\n",
       " 'milk',\n",
       " 'approached',\n",
       " 'pouring',\n",
       " 'attendance',\n",
       " 'rubber',\n",
       " 'bathroom',\n",
       " 'badly',\n",
       " 'oh',\n",
       " 'clearly',\n",
       " 'bihh',\n",
       " 'tripped',\n",
       " 'sel-serve',\n",
       " 'pizza',\n",
       " 'fast.by',\n",
       " 'checking',\n",
       " \"'find\",\n",
       " 'anymore',\n",
       " 'mcdouble',\n",
       " 'must',\n",
       " 'embarrassed',\n",
       " 'relative',\n",
       " 'yoghurt',\n",
       " 'dammm',\n",
       " 'que',\n",
       " 'unwelcome',\n",
       " 'mgr',\n",
       " 'substitution',\n",
       " 'revenue',\n",
       " 'bright',\n",
       " 'second',\n",
       " 'toooo',\n",
       " 'longggg',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'ban',\n",
       " '2-3',\n",
       " 'microwaved',\n",
       " 'ordered',\n",
       " 'byscayne',\n",
       " 'upset',\n",
       " 'stretch',\n",
       " 'crackdonalds',\n",
       " '15/hr',\n",
       " 'control',\n",
       " 'etc',\n",
       " 'opening',\n",
       " 'duty',\n",
       " 'life',\n",
       " 'screen/interactive',\n",
       " 'coo',\n",
       " 'men',\n",
       " 'proportioned',\n",
       " 'also',\n",
       " 'iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'blame',\n",
       " 'reheat',\n",
       " 'rammed',\n",
       " 'move/pull',\n",
       " 'werenï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'rock',\n",
       " 'rid',\n",
       " 'rigging',\n",
       " 'turtle',\n",
       " 'idk',\n",
       " 'slowed',\n",
       " 'jumper',\n",
       " 'enter',\n",
       " 'calm',\n",
       " 'offered',\n",
       " 'recook',\n",
       " 'spotty',\n",
       " 'shop',\n",
       " 'even',\n",
       " 'opened',\n",
       " 'bothered',\n",
       " 'ileanna',\n",
       " 'cosmetic',\n",
       " 'couteous',\n",
       " 'hitting',\n",
       " 'tortilla',\n",
       " '3:30am',\n",
       " 'correctly',\n",
       " 'killed',\n",
       " 'parent',\n",
       " 'crap',\n",
       " 'completely',\n",
       " 'delicious',\n",
       " 'deters',\n",
       " 'regularly',\n",
       " 'ahhh',\n",
       " 'daunting',\n",
       " 'guessing',\n",
       " 'complained',\n",
       " 'packed',\n",
       " 'treasured',\n",
       " 'pocketing',\n",
       " 'creamer',\n",
       " 'buzzy',\n",
       " 'listen',\n",
       " 'chair',\n",
       " 'minimum',\n",
       " 'bringing',\n",
       " '29',\n",
       " 'existence',\n",
       " 'soaked',\n",
       " 'road',\n",
       " 'loudly',\n",
       " 'monique',\n",
       " 'working',\n",
       " 'charm',\n",
       " 'replaced',\n",
       " 'brilliant',\n",
       " 'fuuuuck',\n",
       " 'unreliable',\n",
       " '{',\n",
       " 'nearby',\n",
       " 'talking',\n",
       " 'defeat',\n",
       " 'eventually',\n",
       " 'numerous',\n",
       " 'beautiful',\n",
       " 'needless',\n",
       " 'normally',\n",
       " 'eats',\n",
       " 'initiative',\n",
       " 'never',\n",
       " 'wow',\n",
       " 'hasnï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'appetite',\n",
       " 'mï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½nager',\n",
       " 'old',\n",
       " 'ice',\n",
       " '16',\n",
       " 'latte',\n",
       " 'remotely',\n",
       " 'broadway',\n",
       " '.......',\n",
       " 'scooped',\n",
       " '21',\n",
       " 'bar',\n",
       " 'hardly',\n",
       " 'filthy',\n",
       " 'later',\n",
       " 'reliable',\n",
       " 'moldy',\n",
       " 'transaction',\n",
       " 'micki',\n",
       " 'fall',\n",
       " 'article',\n",
       " 'kindness',\n",
       " 'shake',\n",
       " 'minus',\n",
       " '2md',\n",
       " 'thrust',\n",
       " 'sympathize',\n",
       " 'scream',\n",
       " 'mic',\n",
       " 'bubbly',\n",
       " 'shorter',\n",
       " 'claimed',\n",
       " 'sassy',\n",
       " 'trash',\n",
       " 'midnight',\n",
       " 'playland',\n",
       " 'earlier',\n",
       " 'right',\n",
       " 'happy',\n",
       " 'get',\n",
       " 'frozen',\n",
       " 'refuse',\n",
       " 'next',\n",
       " 'buy',\n",
       " 'hash',\n",
       " 'olga',\n",
       " 'w',\n",
       " 'friendliness',\n",
       " 'elsewhere',\n",
       " 'rare',\n",
       " 'sent',\n",
       " 'wknd',\n",
       " 'owned',\n",
       " '@',\n",
       " 'note',\n",
       " 'rip',\n",
       " 'nan',\n",
       " 'iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'pit',\n",
       " '4:28am',\n",
       " 'decides',\n",
       " 'kill',\n",
       " 'refrigerate',\n",
       " 'heart',\n",
       " 're-opened',\n",
       " 'closed',\n",
       " 'management',\n",
       " 'enjoyed',\n",
       " 'invite',\n",
       " 'million',\n",
       " '10pc',\n",
       " 'check',\n",
       " 'humm',\n",
       " '100',\n",
       " 'nuggets-',\n",
       " 'noticed',\n",
       " 'hilton',\n",
       " 'ca',\n",
       " 'rushing',\n",
       " 'okay',\n",
       " 'hi-c',\n",
       " 'limited',\n",
       " 'like',\n",
       " 'itï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'command',\n",
       " 'climbing',\n",
       " 'didnï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'ibs',\n",
       " 'beckham',\n",
       " 'screaming',\n",
       " 'extended',\n",
       " 'pocket',\n",
       " '8pm',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'proceeds',\n",
       " 'syrup',\n",
       " 'satisfied',\n",
       " 'lane',\n",
       " 'struggle',\n",
       " 'new',\n",
       " 'manegers',\n",
       " 'meat',\n",
       " 'mystery',\n",
       " 'equipment',\n",
       " 'reasonable',\n",
       " 'truly',\n",
       " '3-30-2016',\n",
       " '15.00',\n",
       " 'breakfast.food',\n",
       " 'exelent',\n",
       " 'open',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'and/or',\n",
       " 'acceptable',\n",
       " 'specially',\n",
       " 'blue',\n",
       " 'insane',\n",
       " 'paying',\n",
       " 'cow',\n",
       " 'flood',\n",
       " 'accident',\n",
       " 'irlo',\n",
       " 'blew',\n",
       " 'littered',\n",
       " 'direction',\n",
       " 'fort',\n",
       " 'may',\n",
       " 'send',\n",
       " 'ýýý',\n",
       " 'correctness',\n",
       " 'time.ï¿½ï¿½ï¿',\n",
       " 'fried',\n",
       " 'safeguard',\n",
       " 'narrow',\n",
       " '24/7',\n",
       " 'favorite',\n",
       " 'dont',\n",
       " 'quality',\n",
       " 'smelled',\n",
       " 'raining',\n",
       " 'filtered',\n",
       " 'staffing',\n",
       " 'stg',\n",
       " 'completly',\n",
       " 'besttt',\n",
       " 'kethup',\n",
       " 'sided',\n",
       " 'describe',\n",
       " 'plenty',\n",
       " 'brightens',\n",
       " 'happend',\n",
       " 'indicates',\n",
       " 'famous',\n",
       " 'concerned',\n",
       " 'nope',\n",
       " 'happier',\n",
       " 'acepted',\n",
       " 'laid',\n",
       " 'dispenses',\n",
       " 'stupid',\n",
       " 'regular',\n",
       " 'food',\n",
       " 'oh-kay',\n",
       " 'berate',\n",
       " 'nonchalant',\n",
       " 'worrying',\n",
       " 'wanted',\n",
       " 'spicys',\n",
       " 'coworker',\n",
       " 'burned',\n",
       " 'reading',\n",
       " 'press',\n",
       " 'blocking',\n",
       " 'safari',\n",
       " 'takeout',\n",
       " 'run',\n",
       " 'theyï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'completed',\n",
       " '2',\n",
       " 'infront',\n",
       " 'filling',\n",
       " 'vagrant',\n",
       " 'day',\n",
       " 'pop',\n",
       " 'tie',\n",
       " '10mins',\n",
       " 'much',\n",
       " 'ling',\n",
       " 'wth',\n",
       " 'consider',\n",
       " 'repeatedly',\n",
       " 'size',\n",
       " 'nicely',\n",
       " 'noting',\n",
       " 'popeye',\n",
       " 'conversation',\n",
       " 'canceled',\n",
       " '10-20',\n",
       " 'street',\n",
       " 'seems',\n",
       " 'inattentive',\n",
       " 'vegan',\n",
       " '1786',\n",
       " 'atmosphere',\n",
       " 'arm',\n",
       " 'themed',\n",
       " 'assistant',\n",
       " 'drew',\n",
       " 'crappy',\n",
       " 'bigmacs',\n",
       " 'four',\n",
       " 'ignorant',\n",
       " 'honking',\n",
       " 'dinning',\n",
       " 'involving',\n",
       " 'heavy',\n",
       " 'can',\n",
       " 'hr',\n",
       " 'limit',\n",
       " 'soiled',\n",
       " 'gainesville',\n",
       " 'monitor',\n",
       " 'nuggies',\n",
       " 'cu',\n",
       " 'swamped',\n",
       " 'pay',\n",
       " '106ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½f',\n",
       " 'coke',\n",
       " 'boy',\n",
       " 'preparing',\n",
       " '1/4',\n",
       " 'listening',\n",
       " 'situated',\n",
       " 'cutely',\n",
       " 'word',\n",
       " 'disappeared',\n",
       " 'soap',\n",
       " 'handing',\n",
       " 'ny',\n",
       " '3x',\n",
       " 'ppl',\n",
       " 'disappointed',\n",
       " 'lol',\n",
       " 'bum',\n",
       " 'weigh',\n",
       " 'sp',\n",
       " 'lie',\n",
       " 'desk',\n",
       " 'sometimy',\n",
       " 'yearly',\n",
       " 'personally',\n",
       " 'abandoned',\n",
       " 'dripping',\n",
       " 'package',\n",
       " '10pm',\n",
       " 'fast',\n",
       " 'in-law',\n",
       " 'mcchicken',\n",
       " 'gas',\n",
       " 'melissa',\n",
       " 'irma',\n",
       " 'postive',\n",
       " 'becarefull',\n",
       " 'randomly',\n",
       " 'separated',\n",
       " 'familiar',\n",
       " 'help',\n",
       " 'fed',\n",
       " 'didnï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½t',\n",
       " 'dropped',\n",
       " 'nevada',\n",
       " 'throwed',\n",
       " '.',\n",
       " 'fillet',\n",
       " 'w/o',\n",
       " 'inside',\n",
       " 'coverage',\n",
       " 'food.which',\n",
       " 'girl',\n",
       " 'menï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'fab',\n",
       " 'driveway',\n",
       " 'cheeseburger',\n",
       " 'cheez',\n",
       " 'depending',\n",
       " 'stink',\n",
       " 'brisk',\n",
       " 'possible',\n",
       " 'weave',\n",
       " 'tomatoe',\n",
       " 'rarely',\n",
       " 'closest',\n",
       " 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'surprising',\n",
       " 'sandwich',\n",
       " 'ordef',\n",
       " 'wendys',\n",
       " 'tomato',\n",
       " 'operate',\n",
       " 'bread',\n",
       " 'manager',\n",
       " 'confronted',\n",
       " 'unsanitarity',\n",
       " 'aweso.e',\n",
       " 'late',\n",
       " 'response',\n",
       " 'watered',\n",
       " 'ticking',\n",
       " 'mcdonaldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'lukewarm',\n",
       " 'apologized',\n",
       " 'lose',\n",
       " 'canï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½t',\n",
       " 'redeem',\n",
       " 'shuff',\n",
       " 'nobody',\n",
       " 'whopper',\n",
       " 'came',\n",
       " 'raised',\n",
       " 'houston',\n",
       " 'juat',\n",
       " 'alberta',\n",
       " 'suggest',\n",
       " 'act',\n",
       " 'dint',\n",
       " 'damn',\n",
       " 'carolina',\n",
       " 'favor',\n",
       " 'reflect',\n",
       " '.must',\n",
       " '3',\n",
       " 'attitude',\n",
       " 'fastest',\n",
       " 'entertainment',\n",
       " 'fay',\n",
       " '11:55',\n",
       " 'hamburg',\n",
       " 'curve',\n",
       " '330',\n",
       " 'chandler',\n",
       " 'ripping',\n",
       " 'laughed',\n",
       " 'whiping',\n",
       " '20-30',\n",
       " 'wo/mustard',\n",
       " 'tha',\n",
       " 'point',\n",
       " 'food.ï¿½ï¿½ï¿',\n",
       " 'unhappy',\n",
       " 'planted',\n",
       " 'catch',\n",
       " 'black',\n",
       " 'opportunity',\n",
       " 'haitian',\n",
       " 'cuz',\n",
       " 'koish',\n",
       " 'lil',\n",
       " 'burrito',\n",
       " 'poisoning',\n",
       " 'spirit',\n",
       " 'come',\n",
       " 'checked',\n",
       " 'july',\n",
       " 'brought',\n",
       " 'kool',\n",
       " 'obvious',\n",
       " 'mindset',\n",
       " 'beautifully',\n",
       " 'quarter',\n",
       " 'busy',\n",
       " 'notified',\n",
       " 'move',\n",
       " 'dismissive',\n",
       " 'minor',\n",
       " 'assume',\n",
       " 'sanwhich',\n",
       " 'plum',\n",
       " 'behind',\n",
       " 'group',\n",
       " 'allowed',\n",
       " 'am-',\n",
       " '7pm',\n",
       " 'hurry',\n",
       " 'disguting',\n",
       " 'spent',\n",
       " 'dissatisfying',\n",
       " 'transmitted',\n",
       " 'skim',\n",
       " 'con',\n",
       " 'arrogant',\n",
       " 'jump',\n",
       " 'sloooowww',\n",
       " 'cordial',\n",
       " 'plain',\n",
       " 'front',\n",
       " 'faster',\n",
       " 'traditional',\n",
       " '9/3/18',\n",
       " 'legit',\n",
       " 'itï¿½ï¿½ï¿½',\n",
       " 'lately',\n",
       " 'fluid',\n",
       " 'spaghetti',\n",
       " 'team',\n",
       " 'downloaded',\n",
       " 'chick-fil-a',\n",
       " 'small',\n",
       " 'underpaid',\n",
       " 'undercooked',\n",
       " 'almost',\n",
       " '6:15pm',\n",
       " 'store',\n",
       " 'worry',\n",
       " 'expediente',\n",
       " '2018',\n",
       " 'fork',\n",
       " 'cheated',\n",
       " 'caring',\n",
       " 'bus',\n",
       " 'apologizing',\n",
       " 'mcdonaldï¿½ï¿',\n",
       " '--',\n",
       " 'therw',\n",
       " 'carryout',\n",
       " 'usless',\n",
       " 'pan',\n",
       " 'cost',\n",
       " '0.50',\n",
       " 'recognized',\n",
       " 'diner',\n",
       " 'cute',\n",
       " 'feature',\n",
       " 'severance',\n",
       " 'showing',\n",
       " 'food.great',\n",
       " 'started',\n",
       " 'installed',\n",
       " 'downloading',\n",
       " 'prince',\n",
       " 'manned',\n",
       " 'played',\n",
       " 'shopping',\n",
       " 'bigger',\n",
       " 'kind',\n",
       " 'separate',\n",
       " 'horrendous',\n",
       " 'annoying',\n",
       " '.food',\n",
       " 'felt',\n",
       " 'tat',\n",
       " 'emma',\n",
       " 'majestic',\n",
       " 'wal-mart',\n",
       " 'background',\n",
       " 'splendas',\n",
       " 'appetizer',\n",
       " 'wash',\n",
       " 'vehicle',\n",
       " 'turning',\n",
       " 'humiliates',\n",
       " 'aware',\n",
       " 'cared',\n",
       " 'willing',\n",
       " 'golden',\n",
       " 'head-on',\n",
       " 'freshness',\n",
       " 'known',\n",
       " '2nd',\n",
       " 'atention',\n",
       " 'bottom',\n",
       " 'prefer',\n",
       " '340',\n",
       " 'ferrari',\n",
       " 'donï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿',\n",
       " 'iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'conference',\n",
       " 'counting',\n",
       " 'broken',\n",
       " 'itï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï',\n",
       " 'place',\n",
       " '10/9',\n",
       " 'wel',\n",
       " 'lincoln',\n",
       " 'horrifically',\n",
       " 'avoid',\n",
       " 'row',\n",
       " 'dispenser',\n",
       " 'general',\n",
       " 'take',\n",
       " 'unwanted',\n",
       " 'especially',\n",
       " 'dis',\n",
       " 'yea',\n",
       " 'bacon',\n",
       " 'stopped',\n",
       " 'mean',\n",
       " 'treatsonly',\n",
       " 'bbq',\n",
       " 'salmon',\n",
       " 'tarter',\n",
       " 'so-so',\n",
       " 'hostile',\n",
       " 'aside',\n",
       " 'bank',\n",
       " 'maybeï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½',\n",
       " 'eater',\n",
       " 'experience',\n",
       " 'lunch',\n",
       " 'afford',\n",
       " 'grill',\n",
       " 'knew',\n",
       " '90',\n",
       " 'frequent',\n",
       " 'padded',\n",
       " 'dislike',\n",
       " 'list',\n",
       " 'overly',\n",
       " 'call',\n",
       " 'fraud',\n",
       " 'buyer',\n",
       " 'caramel',\n",
       " 'possibly',\n",
       " '4+',\n",
       " 'stealing',\n",
       " 'iï¿½ï¿½ï¿½ï¿½ï¿½ï',\n",
       " '........',\n",
       " 'indignant',\n",
       " 'rain',\n",
       " 'cooking',\n",
       " 'whatapps',\n",
       " 'stating',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3badc1fc-a687-4e19-81fd-da4c1d23aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(tokens):\n",
    "    vec = [0] * len(vocab)\n",
    "    token_counts = Counter(tokens)\n",
    "    for idx, word in enumerate(vocab):\n",
    "        vec[idx] = token_counts[word]\n",
    "    return vec\n",
    "\n",
    "df['vector'] = df['tokens'].apply(text_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f4ee687-64d0-41db-a6a4-bba94456fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "test_df = df.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a957eb-846f-4022-ac6d-78493789a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf7f9b7-8014-4775-bdbf-132e7740902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_num</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love your coffee</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[love, coffee]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did not like the format of the store, the bathroom is kept closed.</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[like, format, store, ,, bathroom, kept, closed, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rico and his hot and delicious muffin sausages as always the only thing they don't put napkins or ketchup or spicy sauce</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[rico, hot, delicious, muffin, sausage, always, thing, n't, put, napkin, ketchup, spicy, sauce]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad service and they always forget to put the complete order, there is always something missing even meat in the hamburger</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[bad, service, always, forget, put, complete, order, ,, always, something, missing, even, meat, hamburger]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought two meals from them for my friends, and they gave me bread and cheese in exchange for meat. Hahahaha, and the account came out with 30 dollars. Damn the mother of fraud</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[bought, two, meal, friend, ,, gave, bread, cheese, exchange, meat, ., hahahaha, ,, account, came, 30, dollar, ., damn, mother, fraud]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                             reviews  \\\n",
       "0                                                                                                                                                                 I love your coffee   \n",
       "1                                                                                                               I did not like the format of the store, the bathroom is kept closed.   \n",
       "2                                                           Rico and his hot and delicious muffin sausages as always the only thing they don't put napkins or ketchup or spicy sauce   \n",
       "3                                                         Bad service and they always forget to put the complete order, there is always something missing even meat in the hamburger   \n",
       "4  I bought two meals from them for my friends, and they gave me bread and cheese in exchange for meat. Hahahaha, and the account came out with 30 dollars. Damn the mother of fraud   \n",
       "\n",
       "    rating  rating_num     label  \\\n",
       "0  5 stars           5  Positive   \n",
       "1  3 stars           3   Neutral   \n",
       "2  5 stars           5  Positive   \n",
       "3   1 star           1  Negative   \n",
       "4   1 star           1  Negative   \n",
       "\n",
       "                                                                                                                                   tokens  \\\n",
       "0                                                                                                                          [love, coffee]   \n",
       "1                                                                                     [like, format, store, ,, bathroom, kept, closed, .]   \n",
       "2                                         [rico, hot, delicious, muffin, sausage, always, thing, n't, put, napkin, ketchup, spicy, sauce]   \n",
       "3                              [bad, service, always, forget, put, complete, order, ,, always, something, missing, even, meat, hamburger]   \n",
       "4  [bought, two, meal, friend, ,, gave, bread, cheese, exchange, meat, ., hahahaha, ,, account, came, 30, dollar, ., damn, mother, fraud]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d084654-a346-4b8c-97c9-23c9e966ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Accuracy (Based on PDF Logic): 84.01%\n",
      "                                                                                                                                                                                reviews  \\\n",
      "0                                                                                                                                                                    I love your coffee   \n",
      "1                                                                                                                  I did not like the format of the store, the bathroom is kept closed.   \n",
      "2                                                              Rico and his hot and delicious muffin sausages as always the only thing they don't put napkins or ketchup or spicy sauce   \n",
      "3                                                            Bad service and they always forget to put the complete order, there is always something missing even meat in the hamburger   \n",
      "4     I bought two meals from them for my friends, and they gave me bread and cheese in exchange for meat. Hahahaha, and the account came out with 30 dollars. Damn the mother of fraud   \n",
      "...                                                                                                                                                                                 ...   \n",
      "3290                                                                                                                                                        They treated me very badly.   \n",
      "3291                                                                                                                                                           The service is very good   \n",
      "3292                                                                                                                                                         To remove hunger is enough   \n",
      "3293                                                                                                                                It's good, but lately it has become very expensive.   \n",
      "3294                                                                                                                                                          they took good care of me   \n",
      "\n",
      "         label nb_predicted  \n",
      "0     Positive     Positive  \n",
      "1      Neutral     Negative  \n",
      "2     Positive     Positive  \n",
      "3     Negative     Negative  \n",
      "4     Negative     Negative  \n",
      "...        ...          ...  \n",
      "3290  Negative     Negative  \n",
      "3291  Positive     Positive  \n",
      "3292  Positive     Positive  \n",
      "3293  Positive     Positive  \n",
      "3294  Positive     Positive  \n",
      "\n",
      "[3295 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "class_counts = Counter(train_df['label'])\n",
    "total_docs = len(df)\n",
    "priors = {label: count / total_docs for label, count in class_counts.items()}\n",
    "\n",
    "\n",
    "word_counts = {label: Counter() for label in class_counts}\n",
    "for i, row in train_df.iterrows():\n",
    "    word_counts[row['label']].update(row['tokens'])\n",
    "\n",
    "\n",
    "total_words_per_class = {label: sum(words.values()) for label, words in word_counts.items()}\n",
    "\n",
    "\n",
    "vocab = set()\n",
    "for words in word_counts.values():\n",
    "    vocab.update(words.keys())\n",
    "vocab = list(vocab)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "def predict_naive_bayes(tokens):\n",
    "    scores = {}\n",
    "    for label in class_counts:\n",
    "        log_prob = math.log(priors[label])  \n",
    "        for word in tokens:\n",
    "            word_freq = word_counts[label][word]\n",
    "            prob = (word_freq + 1) / (total_words_per_class[label] + vocab_size)\n",
    "            log_prob += math.log(prob)\n",
    "        scores[label] = log_prob\n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "\n",
    "df['nb_predicted'] = df['tokens'].apply(predict_naive_bayes)\n",
    "\n",
    "\n",
    "accuracy = (df['nb_predicted'] == df['label']).mean()\n",
    "print(f\"\\nNaive Bayes Accuracy (Based on PDF Logic): {round(accuracy * 100, 2)}%\")\n",
    "print(df[['reviews', 'label', 'nb_predicted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91be2755-11e6-43b5-a01f-dff7a57d0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(v1, v2):\n",
    "    dot_product = sum(a * b for a, b in zip(v1, v2))\n",
    "    norm1 = math.sqrt(sum(a * a for a in v1))\n",
    "    norm2 = math.sqrt(sum(b * b for b in v2))\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 1 \n",
    "    return 1 - (dot_product / (norm1 * norm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "389fe488-8148-403c-9104-fd73b3842841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Accuracy on Test Set: 78.91%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_sentiment_knn_test(vector, k=3):\n",
    "    distances = []\n",
    "    for i in train_df.index:\n",
    "        dist = cosine_distance(vector, train_df.loc[i, 'vector'])\n",
    "        distances.append((dist, train_df.loc[i, 'label']))\n",
    "    neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "    labels = [label for _, label in neighbors]\n",
    "    most_common = Counter(labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "\n",
    "test_df['knn_predicted'] = test_df['vector'].apply(lambda vec: predict_sentiment_knn_test(vec, k=3))\n",
    "\n",
    "\n",
    "knn_accuracy = (test_df['knn_predicted'] == test_df['label']).mean()\n",
    "print(f\"\\nKNN Accuracy on Test Set: {round(knn_accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ba3ca2-a170-4018-92ac-fb62e735a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a customer review:  The service is horrible at this location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentiment Predictions ---\n",
      "Naive Bayes Prediction: Negative\n",
      "KNN Prediction (k=3): Negative\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"\\nEnter a customer review: \")\n",
    "\n",
    "\n",
    "user_tokens = preprocess(user_input)\n",
    "\n",
    "\n",
    "def vectorize_user_input(tokens):\n",
    "    vec = [0] * len(vocab)\n",
    "    token_counts = Counter(tokens)\n",
    "    for idx, word in enumerate(vocab):\n",
    "        vec[idx] = token_counts[word]\n",
    "    return vec\n",
    "\n",
    "user_vector = vectorize_user_input(user_tokens)\n",
    "\n",
    "\n",
    "nb_result = predict_naive_bayes(user_tokens)\n",
    "\n",
    "\n",
    "def predict_knn_for_input(vector, k=3):\n",
    "    distances = []\n",
    "    for i in df.index:\n",
    "        dist = cosine_distance(vector, df.loc[i, 'vector'])\n",
    "        distances.append((dist, df.loc[i, 'label']))\n",
    "    neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "    labels = [label for _, label in neighbors]\n",
    "    most_common = Counter(labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "knn_result = predict_knn_for_input(user_vector)\n",
    "\n",
    "\n",
    "print(\"\\n--- Sentiment Predictions ---\")\n",
    "print(f\"Naive Bayes Prediction: {nb_result}\")\n",
    "print(f\"KNN Prediction (k=3): {knn_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c83d44-c1a8-4d58-8078-9195dc6c088a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
